{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(clf, data):\n",
    "        accu_train = []\n",
    "        accu_test = []\n",
    "        loss_train = []\n",
    "        loss_test = []    \n",
    "        t_last = []  \n",
    "        train_X, train_Y, test_X, test_Y = data['train_X'], data['train_Y'], data['test_X'], data['test_Y']\n",
    "        \n",
    "        for j in range(0, repeat_times):\n",
    "            t_begin = time.time()\n",
    "\n",
    "            clf.fit(train_X, train_Y)           \n",
    "\n",
    "            predict_train_Y = clf.predict(train_X)\n",
    "            predict_test_Y = clf.predict(test_X)        \n",
    "            t_last.append(time.time() - t_begin)\n",
    "\n",
    "            posterior_train_Y = clf.predict_proba(train_X)\n",
    "            posterior_test_Y = clf.predict_proba(test_X)\n",
    "\n",
    "            accu_train.append(accuracy_score(predict_train_Y, train_Y))\n",
    "            accu_test.append(accuracy_score(predict_test_Y, test_Y))\n",
    "\n",
    "            loss_train.append(log_loss(train_Y, posterior_train_Y, normalize=True))\n",
    "            loss_test.append(log_loss(test_Y, posterior_test_Y, normalize=True))\n",
    "\n",
    "        cnf_matrix_train = confusion_matrix(predict_train_Y, data['train_Y'])\n",
    "        print('[INFO] confusion matrix', cnf_matrix_train)\n",
    "       \n",
    "        cnf_matrix_test = confusion_matrix(predict_test_Y, data['test_Y'])         \n",
    "        print('[INFO] confusion matrix', cnf_matrix_test)      \n",
    "\n",
    "        accu_train = round(np.mean(accu_train), 4)\n",
    "        accu_test = round(np.mean(accu_test), 4)\n",
    "        loss_train = round(np.mean(loss_train), 4)\n",
    "        loss_test = round(np.mean(loss_test), 4)\n",
    "        t_last = round(np.mean(t_last)*1000, 4)\n",
    "        \n",
    "        ''' report train and test error '''\n",
    "        print('Average training data accuracy:', accu_train)\n",
    "        print('Average testing data accuracy:', accu_test)\n",
    "\n",
    "        ''' report train and test log loss'''\n",
    "        print('Average training data log loss:', loss_train)\n",
    "        print('Average testing data log loss:', loss_test) \n",
    "        print('Average Time ms', t_last)\n",
    "        \n",
    "        return accu_train, accu_test, loss_train, loss_test, t_last, cnf_matrix_train, cnf_matrix_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes = np.array([0, 1])\n",
    "\n",
    "title = ['breast-cancer', 'diabetes', 'digit', 'iris', 'wine']\n",
    "plot_args = [{'c': 'red', 'linestyle': '-'},\n",
    "             {'c': 'blue', 'linestyle': '-'}]\n",
    "mode = ['Training data set', 'Testing data set']\n",
    "\n",
    "\n",
    "def plot_performance(loss, accu_train, accu_test, i):\n",
    "    \n",
    "#     ax = plt.subplot(2, 3, i+1)\n",
    "#     epoh = np.linspace(1,len(loss),len(loss))\n",
    "#     ax.plot(epoh, loss, 'm-')\n",
    "            \n",
    "#     plt.title('Performance over time on '+title[i])\n",
    "#     plt.ylabel('Log Loss') \n",
    "#     plt.xlim(-1,np.max(epoh))\n",
    "#     plt.xlabel('Training Epochs')\n",
    "#     plt.rc('xtick', labelsize=10)\n",
    "#     plt.rc('ytick', labelsize=10)\n",
    "    \n",
    "    \n",
    "    ax = plt.subplot(2, 3, i+1)\n",
    "    epoh = np.linspace(1,len(accu_train),len(accu_train))\n",
    "    ax.plot(epoh, accu_train, 'r-')\n",
    "    ax.plot(epoh, accu_test, 'b-')\n",
    "            \n",
    "    plt.title('Performance over time on '+title[i])\n",
    "    plt.ylabel('Classification Accuracy') \n",
    "    plt.xlim(-1,np.max(epoh))\n",
    "    plt.xlabel('Training Epochs')\n",
    "    plt.rc('xtick', labelsize=10)\n",
    "    plt.rc('ytick', labelsize=10)\n",
    "    fig.legend(ax.get_lines(), mode, ncol=2, loc=\"upper center\")                 \n",
    "                       \n",
    "    \n",
    "def partial_train_test(clf, data):\n",
    "        loss = []\n",
    "        accu_train = []\n",
    "        accu_test = []\n",
    "        t_last = []             \n",
    "        train_X, train_Y, test_X, test_Y = data['train_X'], data['train_Y'], data['test_X'], data['test_Y']\n",
    "#         mini_batch_num = batch_num\n",
    "        \n",
    "        for i in range(1, iters):        \n",
    "            for X, Y in zip(np.array_split(train_X, batch_num), np.array_split(train_Y, batch_num)):\n",
    "                t_begin = time.time()\n",
    "    #             clf.fit(X, Y)\n",
    "                clf.partial_fit(X, Y, classes=classes)           \n",
    "            \n",
    "                # loss \n",
    "                loss.append(log_loss(train_Y, clf.predict(train_X), normalize=True))            \n",
    "\n",
    "                # accuracy on train & test data\n",
    "                accu_train.append(clf.score(train_X, train_Y))\n",
    "                accu_test.append(clf.score(test_X, test_Y))\n",
    "\n",
    "                # time required for learning and testing\n",
    "                t_last.append(time.time() - t_begin)            \n",
    "                        \n",
    "#             iterations.append(clf.n_iter_)\n",
    "        print(clf.score(train_X, train_Y)*100)\n",
    "        print(log_loss(train_Y, clf.predict(train_X), normalize=True))\n",
    "        print(clf.score(test_X, test_Y)*100)\n",
    "        print(log_loss(test_Y, clf.predict(test_X), normalize=True))\n",
    "        print(np.sum(t_last)*1000, 'ms')\n",
    "           \n",
    "        return loss, accu_train, accu_test, t_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "def output_csv(result):\n",
    "    fieldnames = result[0,:]\n",
    "    with open('experiment_result/log_reg.csv', 'w') as csvfile:   \n",
    "        resultwriter = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        resultwriter.writeheader()\n",
    "        for i in range(1, result.shape[0]):\n",
    "            dict = {}\n",
    "            for j in range(result.shape[1]):\n",
    "                 dict[result[0,j]] = result[i,j]\n",
    "            resultwriter.writerow(dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module 1: setting the parameters\n",
    "m_i = 1000\n",
    "c = 0.001\n",
    "p = \"l2\"\n",
    "eta = 0.01\n",
    "learning_rate='constant'\n",
    "repeat_times = 100\n",
    "file_count = 5\n",
    "class_names = ['0', '1']\n",
    "batch_num = 20\n",
    "iters = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from:  breast-cancer\n",
      "[INFO] confusion matrix [[178   7]\n",
      " [ 13 349]]\n",
      "[INFO] confusion matrix [[45  2]\n",
      " [ 3 86]]\n",
      "Average training data accuracy: 0.9657\n",
      "Average testing data accuracy: 0.9632\n",
      "Average training data log loss: 0.0916\n",
      "Average testing data log loss: 0.078\n",
      "Average Time ms 1.1655\n",
      "m_i 1000 c 0.001 learning rate 0.01 p l2 t 100 a_train 96.57 a_test 96.32 loss_train 0.0916 loss_test 0.078 time=train+test 1.1655 ms\n",
      "Confusion matrix, without normalization\n",
      "[[178   7]\n",
      " [ 13 349]]\n",
      "Confusion matrix, without normalization\n",
      "[[45  2]\n",
      " [ 3 86]]\n",
      "Reading data from:  diabetes\n",
      "[INFO] confusion matrix [[117  47]\n",
      " [ 97 354]]\n",
      "[INFO] confusion matrix [[34 13]\n",
      " [20 86]]\n",
      "Average training data accuracy: 0.7652\n",
      "Average testing data accuracy: 0.7822\n",
      "Average training data log loss: 0.4821\n",
      "Average testing data log loss: 0.5043\n",
      "Average Time ms 1.2469\n",
      "m_i 1000 c 0.001 learning rate 0.01 p l2 t 100 a_train 76.52 a_test 78.22 loss_train 0.4821 loss_test 0.5043 time=train+test 1.2469 ms\n",
      "Confusion matrix, without normalization\n",
      "[[117  47]\n",
      " [ 97 354]]\n",
      "Confusion matrix, without normalization\n",
      "[[34 13]\n",
      " [20 86]]\n",
      "Reading data from:  digit\n",
      "[INFO] confusion matrix [[396 103]\n",
      " [ 16 285]]\n",
      "[INFO] confusion matrix [[88 28]\n",
      " [ 3 81]]\n",
      "Average training data accuracy: 0.857\n",
      "Average testing data accuracy: 0.8556\n",
      "Average training data log loss: 2.0087\n",
      "Average testing data log loss: 1.9882\n",
      "Average Time ms 1.6696\n",
      "m_i 1000 c 0.001 learning rate 0.01 p l2 t 100 a_train 85.7 a_test 85.56 loss_train 2.0087 loss_test 1.9882 time=train+test 1.6696 ms\n",
      "Confusion matrix, without normalization\n",
      "[[396 103]\n",
      " [ 16 285]]\n",
      "Confusion matrix, without normalization\n",
      "[[88 28]\n",
      " [ 3 81]]\n",
      "Reading data from:  iris\n",
      "[INFO] confusion matrix [[40  0]\n",
      " [ 0 80]]\n",
      "[INFO] confusion matrix [[10  0]\n",
      " [ 0 20]]\n",
      "Average training data accuracy: 1.0\n",
      "Average testing data accuracy: 1.0\n",
      "Average training data log loss: 0.0219\n",
      "Average testing data log loss: 0.0327\n",
      "Average Time ms 0.5119\n",
      "m_i 1000 c 0.001 learning rate 0.01 p l2 t 100 a_train 100.0 a_test 100.0 loss_train 0.0219 loss_test 0.0327 time=train+test 0.5119 ms\n",
      "Confusion matrix, without normalization\n",
      "[[40  0]\n",
      " [ 0 80]]\n",
      "Confusion matrix, without normalization\n",
      "[[10  0]\n",
      " [ 0 20]]\n",
      "Reading data from:  wine\n"
     ]
    }
   ],
   "source": [
    "# Module 2: this module could help you to train and test a classifier\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create a linear classifier\n",
    "clf = SGDClassifier(loss=\"log\", penalty=p, max_iter=m_i, tol=c, \n",
    "                    learning_rate=learning_rate, eta0=eta, verbose=False)\n",
    "clfs = []\n",
    "\n",
    "input_data_filename = ['breast-cancer', 'diabetes', \n",
    "                       'digit', 'iris', \n",
    "                       'wine']\n",
    "result = np.array([['Dataset', '$m\\_i$', '$c$', '$\\eta$', '$p$', '$a_{train}(\\%)$', \n",
    "                    '$a_{test}(\\%)$', '$l_{train}$', '$l_{test}$', '$time(ms)$']])\n",
    "\n",
    "fig, axes=plt.subplots(2, 5, figsize=(15, 10))\n",
    "\n",
    "for i in range(0, file_count):\n",
    "    print('Reading data from: ', input_data_filename[i])\n",
    "    data = np.load('datasets/' + input_data_filename[i] + '.npz')\n",
    "\n",
    "    accu_train, accu_test, loss_train, loss_test, t_last, cnf_matrix_train, cnf_matrix_test = train_test(clf, data)\n",
    "    \n",
    "    ''' report parameters '''\n",
    "    print('m_i', m_i, 'c', c, 'learning rate', eta, 'p', p, 't', repeat_times, \n",
    "          'a_train', accu_train*100, 'a_test', accu_test*100, 'loss_train', loss_train, 'loss_test', loss_test, \n",
    "          'time=train+test', t_last, 'ms')\n",
    "    \n",
    "    plt.subplot(2,5,i+1)\n",
    "    plot_confusion_matrix(cnf_matrix_train, classes=class_names, normalize=False, title=input_data_filename[i]+'_train')\n",
    "    plt.subplot(2,5,5+i+1)\n",
    "    plot_confusion_matrix(cnf_matrix_test, classes=class_names, normalize=False, title=input_data_filename[i]+'_test')\n",
    "    \n",
    "#     print('auc', compute_auc(data['train_Y'], posterior_train_Y[:,1]))\n",
    "    \n",
    "    newrow = np.array([[input_data_filename[i], m_i, c, eta, p, accu_train*100, accu_test*100, loss_train, loss_test, t_last]])\n",
    "    result = np.append(result, newrow, axis=0)\n",
    "    \n",
    "output_csv(result)\n",
    "plt.savefig('log_confusion_matrix.eps', dpi=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Module 3: measuring model's performance overtimes\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create a linear classifier\n",
    "input_data_filename = ['breast-cancer', 'diabetes', \n",
    "                       'digit', 'iris', \n",
    "                       'wine']\n",
    "\n",
    "fig, axes=plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "for i in range(0, file_count):\n",
    "    print('Reading data from: ', input_data_filename[i])\n",
    "    data = np.load('datasets/' + input_data_filename[i] + '.npz')\n",
    "\n",
    "    clf = SGDClassifier(loss=\"log\", penalty=p, max_iter=m_i, tol=c, power_t=0.5, \n",
    "                        learning_rate=learning_rate, eta0=eta, verbose=False)    \n",
    "    \n",
    "    loss, accu_train, accu_test, t_last = partial_train_test(clf, data)\n",
    "    \n",
    "    plot_performance(loss, accu_train, accu_test, i)\n",
    "    \n",
    "plt.savefig('performance_accuracy.eps', dpi=600)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
